{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9Kgm3uP3ZTk"
   },
   "source": [
    "# packages installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JmV3eMqbYgz1",
    "outputId": "7dc7c3dd-9d1b-4cb3-e4e3-5d4eeb1c7630"
   },
   "outputs": [],
   "source": [
    "!pip  install paddleocr paddlepaddle opencv-python-headless pillow langchain-core langchain-text-splitters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Get all installed packages with versions\n",
    "result = subprocess.run(['pip', 'freeze'], capture_output=True, text=True)\n",
    "packages = result.stdout\n",
    "\n",
    "# Write to requirements.txt in the notebook directory\n",
    "ROOT = Path.cwd()\n",
    "req_file = ROOT / 'requirements.txt'\n",
    "with open(req_file, 'w') as f:\n",
    "    f.write(packages)\n",
    "\n",
    "print(f\"✅ Requirements saved to: {req_file}\")\n",
    "print(\"\\n--- Installed Packages ---\\n\")\n",
    "print(packages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env set\n"
     ]
    }
   ],
   "source": [
    "# impainting was crashing gpt gate this cell it idid fix it.\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "print(\"env set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46raWb-3bWJH",
    "outputId": "06ae43ca-aab6-43ad-96c8-44cc045aab4f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmad-jan/Desktop/Markaz/image-translation/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[33mChecking connectivity to the model hosters, this may take a while. To bypass this check, set `DISABLE_MODEL_SOURCE_CHECK` to `True`.\u001b[0m\n",
      "/home/ahmad-jan/Desktop/Markaz/image-translation/venv/lib/python3.12/site-packages/paddle/utils/cpp_extension/extension_utils.py:718: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/ahmad-jan/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/ahmad-jan/.paddlex/official_models/PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/ahmad-jan/.paddlex/official_models/PP-OCRv5_server_rec`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OCR ready (unwarping disabled)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "ocr = PaddleOCR(\n",
    "    lang=\"ch\",\n",
    "    use_doc_unwarping=False,       # ✅ KEY: disable non-linear warp\n",
    "    use_doc_orientation_classify=False,\n",
    "    text_det_limit_type=\"max\",     # limit by max side\n",
    "    text_det_limit_side_len=4000,  # same idea as max_side_limit\n",
    "    text_det_thresh=0.2,\n",
    "    text_det_box_thresh=0.3,\n",
    "    text_det_unclip_ratio=1.8,\n",
    "    text_rec_score_thresh=0.0      # don't drop low confidence\n",
    ")\n",
    "\n",
    "print(\"✅ OCR ready (unwarping disabled)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQf91HA_EeaQ"
   },
   "source": [
    "# ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NsydFCpGBGOy",
    "outputId": "c22c9523-74f5-4ec9-a242-50eeb9ecb3a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook CWD: /home/ahmad-jan/Desktop/Markaz/image-translation/notebook\n",
      "✅ JSON saved in: /home/ahmad-jan/Desktop/Markaz/image-translation/notebook/ocr_nowarp\n",
      "✅ Image fed to OCR: /home/ahmad-jan/Desktop/Markaz/image-translation/notebook/ocr_nowarp/fed_to_ocr.png\n",
      "Input image: /home/ahmad-jan/Desktop/Markaz/image-translation/notebook/img (2).jpeg\n",
      "Boxes: 32\n"
     ]
    }
   ],
   "source": [
    "import os, json, glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "# --- Load ANY common image format into BGR (OpenCV style) ---\n",
    "# CHANGED: force image load before convert to avoid PIL JPEG mode bug\n",
    "# CHANGED: use OpenCV for JPEGs, PIL for everything else\n",
    "\n",
    "def load_image_to_bgr(path: str):\n",
    "    ext = os.path.splitext(path.lower())[1]\n",
    "\n",
    "    # ✅ Use OpenCV for JPEG + WEBP (avoids Pillow WebP bug)\n",
    "    if ext in (\".jpg\", \".jpeg\", \".webp\"):\n",
    "        img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "        if img is None:\n",
    "            raise RuntimeError(f\"OpenCV failed to read image: {path}\")\n",
    "\n",
    "        # If WebP has alpha (BGRA), convert to BGR\n",
    "        if img.ndim == 3 and img.shape[2] == 4:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "        # If grayscale, convert to BGR\n",
    "        if img.ndim == 2:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        return img\n",
    "\n",
    "    # ✅ Pillow for everything else\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    arr = np.array(img)\n",
    "    return cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "def ocr_predict_to_json_keep_input(image_path: str, outdir: str):\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    img_bgr = load_image_to_bgr(image_path)\n",
    "\n",
    "    # Save the exact bitmap we feed to OCR\n",
    "    fed_path = os.path.join(outdir, \"fed_to_ocr.png\")\n",
    "    cv2.imwrite(fed_path, img_bgr)\n",
    "\n",
    "    outputs = ocr.predict(fed_path)\n",
    "    for res in outputs:\n",
    "        res.save_to_json(outdir)\n",
    "\n",
    "    jfiles = sorted(glob.glob(os.path.join(outdir, \"*.json\")), key=os.path.getmtime)\n",
    "    if not jfiles:\n",
    "        raise RuntimeError(\"No JSON produced.\")\n",
    "    with open(jfiles[-1], \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    return data, fed_path\n",
    "\n",
    "\n",
    "# In a notebook, this is your \"base folder\"\n",
    "BASE_DIR = Path.cwd()\n",
    "print(\"Notebook CWD:\", BASE_DIR)\n",
    "\n",
    "# Put your images in this folder (or change it)\n",
    "INPUT_DIR = BASE_DIR  # or: BASE_DIR / \"images\"\n",
    "\n",
    "OUTDIR = BASE_DIR / \"ocr_nowarp\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Pick first image of ANY common format ---\n",
    "exts = (\"*.webp\", \"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\", \"*.tif\", \"*.tiff\")\n",
    "images = []\n",
    "for e in exts:\n",
    "    images += list(INPUT_DIR.glob(e))\n",
    "images = sorted(images)\n",
    "\n",
    "assert images, f\"No images found in: {INPUT_DIR}\"\n",
    "IMAGE_PATH = str(images[0])\n",
    "\n",
    "data, fed_path = ocr_predict_to_json_keep_input(IMAGE_PATH, str(OUTDIR))\n",
    "\n",
    "print(\"✅ JSON saved in:\", OUTDIR)\n",
    "print(\"✅ Image fed to OCR:\", fed_path)\n",
    "print(\"Input image:\", IMAGE_PATH)\n",
    "print(\"Boxes:\", len(data.get(\"rec_boxes\", [])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZ3CIGdHM717"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "CJK_RE = re.compile(r\"[\\u4e00-\\u9fff]\")\n",
    "\n",
    "def get_chinese_items(ocr_json, conf_thresh=None):\n",
    "    \"\"\"\n",
    "    conf_thresh:\n",
    "      - None  => keep ALL chinese (no confidence filtering)\n",
    "      - 0.3   => keep chinese with score >= 0.3\n",
    "    \"\"\"\n",
    "    if not ocr_json:\n",
    "        return []\n",
    "\n",
    "    rec_texts  = ocr_json.get(\"rec_texts\", []) or []\n",
    "    rec_scores = ocr_json.get(\"rec_scores\", []) or []\n",
    "    rec_polys  = ocr_json.get(\"rec_polys\", None)\n",
    "    rec_boxes  = ocr_json.get(\"rec_boxes\", None)\n",
    "\n",
    "    found = []\n",
    "    for i, txt in enumerate(rec_texts):\n",
    "        if not CJK_RE.search(txt or \"\"):\n",
    "            continue\n",
    "\n",
    "        score = float(rec_scores[i]) if i < len(rec_scores) else 0.0\n",
    "        if conf_thresh is not None and score < conf_thresh:\n",
    "            continue\n",
    "\n",
    "        item = {\"text\": txt, \"conf\": score}\n",
    "        if rec_polys is not None and i < len(rec_polys): item[\"poly\"] = rec_polys[i]\n",
    "        if rec_boxes is not None and i < len(rec_boxes): item[\"box\"]  = rec_boxes[i]\n",
    "        found.append(item)\n",
    "\n",
    "    return found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qXVi7AWSNEIT",
    "outputId": "055462fb-352b-4d9c-be4b-b8ab69a80f59"
   },
   "outputs": [],
   "source": [
    "ch_items = get_chinese_items(data, conf_thresh=None)  # keep ALL Chinese\n",
    "print(\"Chinese lines:\", len(ch_items))\n",
    "print(ch_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 846
    },
    "id": "mdHfLlVtS1xg",
    "outputId": "9956b143-8e5e-4eec-e775-a313a4f8752c"
   },
   "outputs": [],
   "source": [
    "# --- Visualize ONLY Chinese detections as rectangles on the exact OCR-fed image ---\n",
    "\n",
    "import cv2, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Collect chinese items (no confidence filter; set e.g. 0.3 if you want)\n",
    "ch_items = get_chinese_items(data, conf_thresh=None)\n",
    "print(\"Chinese boxes:\", len(ch_items))\n",
    "\n",
    "# 2) Load the exact bitmap that was fed to OCR (prevents coordinate drift)\n",
    "img_bgr = cv2.imread(fed_path, cv2.IMREAD_COLOR)\n",
    "assert img_bgr is not None, f\"Could not read: {fed_path}\"\n",
    "H, W = img_bgr.shape[:2]\n",
    "\n",
    "# 3) Draw rectangles\n",
    "vis = img_bgr.copy()\n",
    "\n",
    "def clamp(v, lo, hi):\n",
    "    return int(max(lo, min(hi, v)))\n",
    "\n",
    "for it in ch_items:\n",
    "    if \"box\" not in it or it[\"box\"] is None:\n",
    "        continue\n",
    "\n",
    "    # PaddleOCR rec_boxes usually: [x1, y1, x2, y2]\n",
    "    x1, y1, x2, y2 = map(float, it[\"box\"])\n",
    "    x1 = clamp(x1, 0, W-1); x2 = clamp(x2, 0, W-1)\n",
    "    y1 = clamp(y1, 0, H-1); y2 = clamp(y2, 0, H-1)\n",
    "\n",
    "    # ensure proper order\n",
    "    if x2 < x1: x1, x2 = x2, x1\n",
    "    if y2 < y1: y1, y2 = y2, y1\n",
    "\n",
    "    cv2.rectangle(vis, (x1, y1), (x2, y2), (0, 255, 0), 3)  # green box, thickness 3\n",
    "\n",
    "# 4) Show\n",
    "vis_rgb = cv2.cvtColor(vis, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.imshow(vis_rgb)\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Chinese detections (rectangles): {len(ch_items)}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_oGLaPY3xga"
   },
   "source": [
    "# translation with llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install -U google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8yfCLT_pXBg"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyAe33GrwIicD5N4JIwxYSO6Nb7b35s2fH4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3WcZ44BpxYsA"
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import os, json, math\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "Translate Chinese OCR lines to English for product images.\n",
    "\n",
    "Rules:\n",
    "- ONE translation per line (no options, no numbering, no explanations).\n",
    "- Keep it SHORT to fit the original box: en length <= max_chars.\n",
    "- Keep repeated terms consistent.\n",
    "- Use simple, short size synonyms to occupy less space for product images.\n",
    "\n",
    "Output JSON ONLY:\n",
    "[{ \"i\": <index>, \"en\": \"<translation>\" }]\n",
    "\"\"\".strip()\n",
    "\n",
    "client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "def translate_items_gemini_min(ch_items, model=\"gemini-2.5-flash\"):\n",
    "    items = []\n",
    "    for i, it in enumerate(ch_items):\n",
    "        cn = (it.get(\"text\") or \"\").strip()\n",
    "        max_chars = max(6, int(len(cn) * 1.35))\n",
    "        items.append({\"i\": i, \"cn\": cn, \"max_chars\": max_chars})\n",
    "\n",
    "    payload = {\"items\": items}\n",
    "\n",
    "    resp = client.models.generate_content(\n",
    "        model=model,\n",
    "        contents=json.dumps(payload, ensure_ascii=False),\n",
    "        config={\n",
    "            \"system_instruction\": SYSTEM_PROMPT,\n",
    "            \"temperature\": 0.2,\n",
    "            \"response_mime_type\": \"application/json\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    arr = json.loads((resp.text or \"\").strip())\n",
    "    mp = {int(o[\"i\"]): (o.get(\"en\") or \"\").strip() for o in arr}\n",
    "    return [mp.get(i, \"\") for i in range(len(items))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C6_7BbNMxccw"
   },
   "outputs": [],
   "source": [
    "en_lines = translate_items_gemini_min(\n",
    "    ch_items,\n",
    "    model=\"models/gemini-flash-lite-latest\",\n",
    ")\n",
    "\n",
    "for it, en in zip(ch_items, en_lines):\n",
    "    \n",
    "    it[\"en\"] = en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"ch_items.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(ch_items, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"ch_items.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    ch_items = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ad_AmY3S0VNk",
    "outputId": "87218364-a52d-4026-83f0-b83534b5e4c0"
   },
   "outputs": [],
   "source": [
    "for i, it in enumerate(ch_items[:15]):\n",
    "    print(f\"[{i}] CN: {it['text']}\")\n",
    "    print(f\"    EN: {it.get('en','')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BV21nsBC4VzL"
   },
   "source": [
    "# text overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install CPU-only PyTorch (avoids 2GB+ CUDA packages)\n",
    "# Then install simple-lama-inpainting\n",
    "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install simple-lama-inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QKpgrYGP7Y2Q",
    "outputId": "31846431-d129-4c2f-a0d9-7fc7db7b031b"
   },
   "outputs": [],
   "source": [
    "\n",
    "from simple_lama_inpainting import SimpleLama\n",
    "import numpy as np\n",
    "\n",
    "simple_lama = SimpleLama()\n",
    "\n",
    "# smoke test\n",
    "dummy_img  = np.zeros((32, 32, 3), dtype=np.uint8)     # RGB/BGR both ok for smoke\n",
    "dummy_mask = np.zeros((32, 32), dtype=np.uint8)\n",
    "dummy_mask[10:22, 10:22] = 255\n",
    "\n",
    "_ = simple_lama(dummy_img, dummy_mask)\n",
    "print(\"✅ SimpleLama imported and callable works.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 838
    },
    "id": "3x5hJ0Rh73yS",
    "outputId": "c77942d6-a129-485d-85cd-3894882d1960"
   },
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from simple_lama_inpainting import SimpleLama\n",
    "\n",
    "ROOT = Path.cwd()                 # notebook root folder\n",
    "print(\"Notebook root:\", ROOT)\n",
    "\n",
    "exts = (\"*.png\",\"*.jpg\",\"*.jpeg\",\"*.webp\",\"*.bmp\",\"*.tif\",\"*.tiff\")\n",
    "imgs = []\n",
    "for e in exts:\n",
    "    imgs += list(ROOT.glob(e))\n",
    "assert imgs, f\"No images found in {ROOT}\"\n",
    "IMAGE_PATH = imgs[0]\n",
    "print(\"Using:\", IMAGE_PATH)\n",
    "\n",
    "\n",
    "img = cv2.imread(str(IMAGE_PATH), cv2.IMREAD_COLOR)\n",
    "assert img is not None, f\"Could not read image: {IMAGE_PATH}\"\n",
    "H, W = img.shape[:2]\n",
    "\n",
    "# 1) Build mask from chinese detections (prefer poly, fallback box)\n",
    "mask = np.zeros((H, W), dtype=np.uint8)\n",
    "\n",
    "for it in ch_items:\n",
    "    if it.get(\"poly\") is not None:\n",
    "        pts = np.array(it[\"poly\"], dtype=np.int32).reshape(-1, 2)\n",
    "        cv2.fillPoly(mask, [pts], 255)\n",
    "    elif it.get(\"box\") is not None:\n",
    "        x1, y1, x2, y2 = map(int, it[\"box\"])\n",
    "        x1, y1 = max(0, x1), max(0, y1)\n",
    "        x2, y2 = min(W - 1, x2), min(H - 1, y2)\n",
    "        if x2 > x1 and y2 > y1:\n",
    "            cv2.rectangle(mask, (x1, y1), (x2, y2), 255, thickness=-1)\n",
    "\n",
    "# 2) Expand mask a bit (covers strokes better)\n",
    "pad = 6\n",
    "k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2*pad + 1, 2*pad + 1))\n",
    "mask = cv2.dilate(mask, k, iterations=1)\n",
    "\n",
    "# 3) Inpaint: SimpleLaMa → fallback OpenCV Telea\n",
    "out = None\n",
    "try:\n",
    "    simple_lama = SimpleLama()\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    inpaint_pil = simple_lama(img_rgb, mask)\n",
    "    out = cv2.cvtColor(np.array(inpaint_pil), cv2.COLOR_RGB2BGR)\n",
    "    print(\"✅ SimpleLaMa inpainting done.\")\n",
    "except Exception as e:\n",
    "    print(\"⚠️ SimpleLaMa failed, falling back to OpenCV inpaint. Error:\", str(e)[:200])\n",
    "    out = cv2.inpaint(img, mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)\n",
    "    print(\"✅ OpenCV inpaint done.\")\n",
    "\n",
    "# --- Save to notebook root ---\n",
    "out_path = ROOT / \"inpaint_no_chinese.png\"\n",
    "cv2.imwrite(str(out_path), out)\n",
    "\n",
    "plt.figure(figsize=(10, 18))\n",
    "plt.imshow(cv2.cvtColor(out, cv2.COLOR_BGR2RGB))\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Inpainted (Chinese removed) | count={len(ch_items)}\")\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to install font.\n",
    "!apt-get -y update -qq\n",
    "!apt-get -y install -qq fonts-dejavu-core\n",
    "\n",
    "import glob, os\n",
    "cands = glob.glob(\"/usr/share/fonts/truetype/dejavu/*.ttf\")\n",
    "print(\"found\", len(cands), \"ttf fonts\")\n",
    "print(cands[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math\n",
    "import cv2, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageFilter\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Base image: use your inpaint result ---\n",
    "ROOT = Path.cwd()\n",
    "base_path = ROOT / \"inpaint_no_chinese.png\"\n",
    "assert os.path.exists(base_path), f\"Missing: {base_path}\"\n",
    "bgr = cv2.imread(str(base_path))\n",
    "assert bgr is not None, \"Could not read inpainted image.\"\n",
    "H, W = bgr.shape[:2]\n",
    "\n",
    "rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "pil_img = Image.fromarray(rgb).convert(\"RGBA\")\n",
    "draw = ImageDraw.Draw(pil_img)\n",
    "\n",
    "# --- Font (use a clean sans; bold is good for small labels) ---\n",
    "font_path = \"/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf\"\n",
    "assert os.path.exists(font_path), f\"Missing font: {font_path}\"\n",
    "\n",
    "# ---------- tunable parameters ----------\n",
    "PAD_IN = 2                   # inner padding inside each box (px)\n",
    "MIN_BOX_W = 20               # boxes narrower than this are skipped\n",
    "MIN_BOX_H = 14               # boxes shorter than this are skipped\n",
    "MIN_FONT_SIZE = 12           # below this, try multi-line\n",
    "MAX_FONT_SIZE = 120          # upper bound for font sizing\n",
    "FONT_SIZE_STEP = 2           # decrement step when searching\n",
    "SPLIT_THRESHOLD = 12         # if single-line font <= this, try 2 lines\n",
    "MAX_LINES_FALLBACK = 2       # max lines when splitting\n",
    "LINE_SPACING = 1.025          # line height multiplier (1.0 = tight, 1.2 = loose)\n",
    "SHADOW_BLUR = 1              # Gaussian blur radius for shadow\n",
    "SHADOW_OFFSET = (1, 1)       # pixel offset for shadow\n",
    "DRAW_DEBUG_BOXES = True      # overlay rectangles for debugging\n",
    "RECT_PAD = 0\n",
    "RECT_COLOR = (255, 64, 64, 200)\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def clamp_box(x1, y1, x2, y2, W, H):\n",
    "    x1 = int(max(0, min(W - 1, x1)))\n",
    "    y1 = int(max(0, min(H - 1, y1)))\n",
    "    x2 = int(max(0, min(W - 1, x2)))\n",
    "    y2 = int(max(0, min(H - 1, y2)))\n",
    "    if x2 < x1:\n",
    "        x1, x2 = x2, x1\n",
    "    if y2 < y1:\n",
    "        y1, y2 = y2, y1\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "\n",
    "def text_size(draw, text, font):\n",
    "    bb = draw.textbbox((0, 0), text, font=font)\n",
    "    return bb[2] - bb[0], bb[3] - bb[1]\n",
    "\n",
    "\n",
    "def wrap_text(draw, text, font, max_w, max_lines=2):\n",
    "    \"\"\"Greedy wrap by spaces; fall back to char wrap.\"\"\"\n",
    "    text = (text or \"\").strip()\n",
    "    if not text:\n",
    "        return []\n",
    "\n",
    "    # Fits on one line?\n",
    "    if text_size(draw, text, font)[0] <= max_w:\n",
    "        return [text]\n",
    "\n",
    "    words = text.split()\n",
    "    if len(words) == 1:\n",
    "        # char wrap for single long word\n",
    "        lines = []\n",
    "        cur = \"\"\n",
    "        for ch in text:\n",
    "            test = cur + ch\n",
    "            if text_size(draw, test, font)[0] <= max_w or not cur:\n",
    "                cur = test\n",
    "            else:\n",
    "                lines.append(cur)\n",
    "                cur = ch\n",
    "                if len(lines) >= max_lines:\n",
    "                    break\n",
    "        if len(lines) < max_lines and cur:\n",
    "            lines.append(cur)\n",
    "        return lines[:max_lines]\n",
    "\n",
    "    # word wrap\n",
    "    lines = []\n",
    "    cur = \"\"\n",
    "    for w in words:\n",
    "        test = (cur + \" \" + w).strip()\n",
    "        if text_size(draw, test, font)[0] <= max_w or not cur:\n",
    "            cur = test\n",
    "        else:\n",
    "            lines.append(cur)\n",
    "            cur = w\n",
    "            if len(lines) >= max_lines:\n",
    "                break\n",
    "    if len(lines) < max_lines and cur:\n",
    "        lines.append(cur)\n",
    "\n",
    "    return lines[:max_lines]\n",
    "\n",
    "\n",
    "def truncate_line_to_width(draw, s, font, max_w):\n",
    "    s = (s or \"\").strip()\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    if text_size(draw, s, font)[0] <= max_w:\n",
    "        return s\n",
    "    ell = \"…\"\n",
    "    if text_size(draw, ell, font)[0] > max_w:\n",
    "        return \"\"\n",
    "    while s and text_size(draw, s + ell, font)[0] > max_w:\n",
    "        s = s[:-1]\n",
    "    return (s + ell) if s else ell\n",
    "\n",
    "\n",
    "def fit_font_single_line(draw, text, target_w, target_h, font_path,\n",
    "                         min_size=10, max_size=200, step=2):\n",
    "    \"\"\"\n",
    "    Try to fit text on ONE line. Returns (font, [line], font_size) or None.\n",
    "    \"\"\"\n",
    "    text = (text or \"\").strip()\n",
    "    if not text:\n",
    "        return None\n",
    "\n",
    "    for sz in range(max_size, min_size - 1, -step):\n",
    "        f = ImageFont.truetype(font_path, sz)\n",
    "        tw, th = text_size(draw, text, f)\n",
    "        if tw <= target_w and th <= target_h:\n",
    "            return f, [text], sz\n",
    "    return None\n",
    "\n",
    "\n",
    "def fit_font_multi_line(draw, text, target_w, target_h, font_path,\n",
    "                        max_lines=2, min_size=10, max_size=200, step=2, line_spacing=1.1):\n",
    "    \"\"\"\n",
    "    Try to fit text wrapped to max_lines. Returns (font, lines, font_size).\n",
    "    \"\"\"\n",
    "    text = (text or \"\").strip()\n",
    "    if not text:\n",
    "        return None\n",
    "\n",
    "    best = None\n",
    "    for sz in range(max_size, min_size - 1, -step):\n",
    "        f = ImageFont.truetype(font_path, sz)\n",
    "        lines = wrap_text(draw, text, f, target_w, max_lines=max_lines)\n",
    "        if not lines:\n",
    "            continue\n",
    "\n",
    "        # truncate any overflowing line\n",
    "        lines = [truncate_line_to_width(draw, li, f, target_w) for li in lines]\n",
    "\n",
    "        line_h = text_size(draw, \"Ag\", f)[1]\n",
    "        total_h = int(line_h * len(lines) * line_spacing)\n",
    "        max_line_w = max(text_size(draw, li, f)[0] for li in lines) if lines else 0\n",
    "\n",
    "        if max_line_w <= target_w and total_h <= target_h:\n",
    "            return f, lines, sz\n",
    "\n",
    "        best = (f, lines, sz)\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "def sample_bg_luma(bgr_img, x1, y1, x2, y2, pad=6):\n",
    "    \"\"\"Sample border region around the box to guess background brightness.\"\"\"\n",
    "    H, W = bgr_img.shape[:2]\n",
    "    x1p = max(0, x1 - pad)\n",
    "    y1p = max(0, y1 - pad)\n",
    "    x2p = min(W, x2 + pad)\n",
    "    y2p = min(H, y2 + pad)\n",
    "    roi = bgr_img[y1p:y2p, x1p:x2p]\n",
    "    if roi.size == 0:\n",
    "        return 255\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    return float(np.median(gray))\n",
    "\n",
    "\n",
    "def draw_text_with_shadow(pil_rgba, xy, lines, font, fill_rgba, shadow_rgba,\n",
    "                          shadow_blur=2, shadow_offset=(1, 1), align=\"center\", line_spacing=1.1):\n",
    "    \"\"\"Draw multi-line text with a soft shadow layer.\"\"\"\n",
    "    base = pil_rgba\n",
    "    x, y = xy\n",
    "    tmp = Image.new(\"RGBA\", base.size, (0, 0, 0, 0))\n",
    "    d = ImageDraw.Draw(tmp)\n",
    "\n",
    "    line_h = d.textbbox((0, 0), \"Ag\", font=font)[3]\n",
    "    widths = [d.textbbox((0, 0), li, font=font)[2] for li in lines]\n",
    "    block_w = max(widths) if widths else 0\n",
    "    step_y = int(line_h * line_spacing)\n",
    "\n",
    "    yy = y\n",
    "    for li, w in zip(lines, widths):\n",
    "        if align == \"center\":\n",
    "            xx = x + (block_w - w) // 2\n",
    "        elif align == \"left\":\n",
    "            xx = x\n",
    "        else:\n",
    "            xx = x + (block_w - w)\n",
    "        d.text((xx + shadow_offset[0], yy + shadow_offset[1]), li, font=font, fill=shadow_rgba)\n",
    "        yy += step_y\n",
    "\n",
    "    tmp = tmp.filter(ImageFilter.GaussianBlur(radius=shadow_blur))\n",
    "\n",
    "    d = ImageDraw.Draw(tmp)\n",
    "    yy = y\n",
    "    for li, w in zip(lines, widths):\n",
    "        if align == \"center\":\n",
    "            xx = x + (block_w - w) // 2\n",
    "        elif align == \"left\":\n",
    "            xx = x\n",
    "        else:\n",
    "            xx = x + (block_w - w)\n",
    "        d.text((xx, yy), li, font=font, fill=fill_rgba)\n",
    "        yy += step_y\n",
    "\n",
    "    block_h = int(line_h * len(lines) * line_spacing)\n",
    "    return Image.alpha_composite(base, tmp), (block_w, block_h)\n",
    "\n",
    "\n",
    "# --- Draw translated English into each detected box ---\n",
    "for it in ch_items:\n",
    "    en = (it.get(\"en\") or \"\").strip()\n",
    "    if not en or it.get(\"box\") is None:\n",
    "        continue\n",
    "\n",
    "    x1, y1, x2, y2 = map(int, it[\"box\"])\n",
    "    x1, y1, x2, y2 = clamp_box(x1, y1, x2, y2, W, H)\n",
    "    bw, bh = (x2 - x1), (y2 - y1)\n",
    "\n",
    "    if bw < MIN_BOX_W or bh < MIN_BOX_H:\n",
    "        continue\n",
    "\n",
    "    target_w = max(1, bw - 2 * PAD_IN)\n",
    "    target_h = max(1, bh - 2 * PAD_IN)\n",
    "\n",
    "    # --- Strategy: try single-line first ---\n",
    "    result = fit_font_single_line(\n",
    "        draw, en, target_w, target_h, font_path,\n",
    "        min_size=MIN_FONT_SIZE, max_size=MAX_FONT_SIZE, step=FONT_SIZE_STEP\n",
    "    )\n",
    "\n",
    "    if result:\n",
    "        font, lines, font_sz = result\n",
    "        # If font size is too small, try multi-line for better visibility\n",
    "        if font_sz <= SPLIT_THRESHOLD:\n",
    "            multi = fit_font_multi_line(\n",
    "                draw, en, target_w, target_h, font_path,\n",
    "                max_lines=MAX_LINES_FALLBACK,\n",
    "                min_size=MIN_FONT_SIZE, max_size=MAX_FONT_SIZE, step=FONT_SIZE_STEP,\n",
    "                line_spacing=LINE_SPACING\n",
    "            )\n",
    "            if multi and multi[2] > font_sz:\n",
    "                font, lines, font_sz = multi\n",
    "    else:\n",
    "        # Single-line failed entirely, try multi-line\n",
    "        multi = fit_font_multi_line(\n",
    "            draw, en, target_w, target_h, font_path,\n",
    "            max_lines=MAX_LINES_FALLBACK,\n",
    "            min_size=MIN_FONT_SIZE, max_size=MAX_FONT_SIZE, step=FONT_SIZE_STEP,\n",
    "            line_spacing=LINE_SPACING\n",
    "        )\n",
    "        if multi:\n",
    "            font, lines, font_sz = multi\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    if not lines:\n",
    "        continue\n",
    "\n",
    "    # Pick text color based on local background brightness\n",
    "    luma = sample_bg_luma(bgr, x1, y1, x2, y2, pad=8)\n",
    "    if luma > 160:\n",
    "        fill = (15, 15, 15, 255)\n",
    "        shadow = (255, 255, 255, 140)\n",
    "    else:\n",
    "        fill = (245, 245, 245, 255)\n",
    "        shadow = (0, 0, 0, 160)\n",
    "\n",
    "    # Compute block size and center it\n",
    "    widths = [draw.textbbox((0, 0), li, font=font)[2] for li in lines]\n",
    "    line_h = draw.textbbox((0, 0), \"Ag\", font=font)[3]\n",
    "    block_w = max(widths) if widths else 0\n",
    "    block_h = int(line_h * len(lines) * LINE_SPACING)\n",
    "\n",
    "    tx = x1 + (bw - block_w) // 2\n",
    "    ty = y1 + (bh - block_h) // 2\n",
    "\n",
    "    pil_img, _ = draw_text_with_shadow(\n",
    "        pil_img,\n",
    "        (tx, ty),\n",
    "        lines,\n",
    "        font,\n",
    "        fill_rgba=fill,\n",
    "        shadow_rgba=shadow,\n",
    "        shadow_blur=SHADOW_BLUR,\n",
    "        shadow_offset=SHADOW_OFFSET,\n",
    "        align=\"center\",\n",
    "        line_spacing=LINE_SPACING,\n",
    "    )\n",
    "\n",
    "# --- Debug overlay: highlight boxes ---\n",
    "# if DRAW_DEBUG_BOXES:\n",
    "#     rect_draw = ImageDraw.Draw(pil_img)\n",
    "#     for it in ch_items:\n",
    "#         if it.get(\"box\") is None:\n",
    "#             continue\n",
    "#         x1, y1, x2, y2 = map(int, it[\"box\"])\n",
    "#         x1, y1, x2, y2 = clamp_box(x1, y1, x2, y2, W, H)\n",
    "#         x1p, y1p, x2p, y2p = clamp_box(x1 - RECT_PAD, y1 - RECT_PAD, x2 + RECT_PAD, y2 + RECT_PAD, W, H)\n",
    "#         rect_draw.rectangle([x1p, y1p, x2p, y2p], outline=RECT_COLOR, width=3)\n",
    "\n",
    "# Save + show\n",
    "final_path = ROOT / \"inpaint_with_english_natural.png\"\n",
    "pil_img.convert(\"RGB\").save(final_path)\n",
    "\n",
    "plt.figure(figsize=(10, 18))\n",
    "plt.imshow(pil_img.convert(\"RGB\"))\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Saved:\", final_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "w9Kgm3uP3ZTk"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
